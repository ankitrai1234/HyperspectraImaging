{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg_Tzsu5gtC1",
        "outputId": "ed8e5895-631f-4d9c-8e1b-4be20d79b994"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Scaler and PCA saved successfully!\n",
            "✅ Input processed: Ready for model prediction!\n",
            "Processed shape: (1, 1, 3)\n"
          ]
        }
      ],
      "source": [
        "#here we use the model we create for prediction\n",
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generate random training data (1000 samples, 448 features)\n",
        "X_train = np.random.uniform(0.25, 0.75, (1000, 448))\n",
        "\n",
        "# Step 1: Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Step 2: Apply PCA (reduce 448 → 3 components)\n",
        "pca = PCA(n_components=3)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Save the trained models\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "joblib.dump(pca, \"pca.pkl\")\n",
        "\n",
        "print(\"✅ Scaler and PCA saved successfully!\")\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# Load the saved scaler and PCA\n",
        "scaler = joblib.load(\"scaler.pkl\")\n",
        "pca = joblib.load(\"pca.pkl\")\n",
        "\n",
        "# Create a new input feature vector (1 sample, 448 features)\n",
        "input_features = np.random.uniform(0.25, 0.75, (1, 448))  # Shape: (1, 448)\n",
        "\n",
        "# Standardize the input\n",
        "input_scaled = scaler.transform(input_features)\n",
        "\n",
        "# Apply PCA transformation (reduces to 3 features)\n",
        "input_pca = pca.transform(input_scaled)\n",
        "\n",
        "# Reshape for feeding into LSTM (if required)\n",
        "input_final = input_pca.reshape((input_pca.shape[0], 1, input_pca.shape[1]))\n",
        "\n",
        "print(\"✅ Input processed: Ready for model prediction!\")\n",
        "print(\"Processed shape:\", input_final.shape)  # Should be (1, 1, 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i24CeK-9uX-C",
        "outputId": "bb8e18a5-d8f0-4d4d-f3ee-baa3527910a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model loaded successfully!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572ms/step\n",
            "✅ Prediction completed!\n",
            "Final Output Shape: (1, 1)\n",
            "Final Output Values: [[5.1169143]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "# Load the trained LSTM model\n",
        "custom_objects = {\"mse\": MeanSquaredError()}\n",
        "model = tf.keras.models.load_model(\"/content/best_lstm_model.h5\", custom_objects=custom_objects)\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# Load the Standard Scaler (for input) & PCA\n",
        "scaler = joblib.load(\"/content/scaler.pkl\")  # StandardScaler for input features\n",
        "pca = joblib.load(\"/content/pca.pkl\")  # PCA for input dimensionality reduction\n",
        "\n",
        "# Load the Output Scaler (for target variable) which was used during prediction\n",
        "output_scaler = joblib.load(\"/content/output_scaler.pkl\")  # StandardScaler for model output\n",
        "\n",
        "#  Generate Random Input (1, 448)\n",
        "input_features = np.random.uniform(0.25, 0.75, (1, 448))\n",
        "\n",
        "# Standardize & Apply PCA\n",
        "input_scaled = scaler.transform(input_features)  # Shape: (1, 448)\n",
        "input_pca = pca.transform(input_scaled)  # Shape: (1, 3)\n",
        "\n",
        "# Reshape for LSTM (Batch=1, Timesteps=1, Features=3)\n",
        "input_final = input_pca.reshape((1, 1, 3))\n",
        "\n",
        "#  Predict using LSTM\n",
        "prediction_scaled = model.predict(input_final)  # LSTM output (in scaled space)\n",
        "\n",
        "#  Reverse Scaling using the target scaler (Not PCA)\n",
        "final_output = output_scaler.inverse_transform(prediction_scaled)  # Convert back to original target scale\n",
        "\n",
        "#  Display Results\n",
        "print(\" Prediction completed!\")\n",
        "print(\"Final Output Shape:\", final_output.shape)  # Should be (1, X) where X matches target shape\n",
        "print(\"Final Output Values:\", final_output)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
